{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed4775a-1250-47bf-9821-208b7d40a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as tvtf\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights, MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "\n",
    "FocalLength = 0.673624570232178\n",
    "weights = MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=weights)\n",
    "model.load_state_dict(torch.load(\"MaskrCNN_model.pt\"))\n",
    "model.eval()\n",
    "centre = None\n",
    "COLOURS = [\n",
    "    tuple(int(colour_hex.strip('#')[i:i + 2], 16) for i in (0, 2, 4))\n",
    "    for colour_hex in plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e78306-e4f1-4586-bb38-96d33f1353ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageColorChange(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tvtf.to_tensor(image)\n",
    "    image = image.unsqueeze(dim=0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_detections(maskrcnn, imgs, score_threshold=0.5):  # person, dog, elephant, zebra, giraffe, toilet\n",
    "    det = []\n",
    "    lbls = []\n",
    "    scores = []\n",
    "    masks = []\n",
    "\n",
    "    for img in imgs:\n",
    "        with torch.no_grad():\n",
    "            result = maskrcnn(preprocess_image(img))[0]\n",
    "        mask = result[\"scores\"] > score_threshold\n",
    "        det.append(result[\"boxes\"][mask].detach().cpu().numpy())\n",
    "        lbls.append(result[\"labels\"][mask].detach().cpu().numpy())\n",
    "        scores.append(result[\"scores\"][mask].detach().cpu().numpy())\n",
    "        masks.append(result[\"masks\"][mask])\n",
    "    return det, lbls, scores, masks\n",
    "\n",
    "\n",
    "def draw_detections(img, det, colours=None, obj_order=None):\n",
    "    # i starts from 0, len(det), (tlx, tly, brx, bry) are position\n",
    "    if colours is None:\n",
    "        colours = COLOURS\n",
    "    for i, (tlx, tly, brx, bry) in enumerate(det):\n",
    "        if obj_order is not None and len(obj_order) < i:\n",
    "            i = obj_order[i]\n",
    "        i %= len(colours)\n",
    "        cv2.rectangle(img, (tlx, tly), (brx, bry), color=colours[i], thickness=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b381c0b-314f-45b4-907c-00b260d3a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tlbr_to_center1(boxes):\n",
    "    points = []\n",
    "    for tlx, tly, brx, bry in boxes:\n",
    "        cx = (tlx + brx) / 2\n",
    "        cy = (tly + bry) / 2\n",
    "        points.append([cx, cy])\n",
    "    return points\n",
    "\n",
    "\n",
    "def tlbr_to_corner(boxes):\n",
    "    points = []\n",
    "    for tlx, tly, brx, bry in boxes:\n",
    "        cx = (tlx + tlx) / 2\n",
    "        cy = (tly + tly) / 2\n",
    "        points.append((cx, cy))\n",
    "    return points\n",
    "\n",
    "\n",
    "def tlbr_to_corner_br(boxes):\n",
    "    points = []\n",
    "    for tlx, tly, brx, bry in boxes:\n",
    "        cx = (brx + brx) / 2\n",
    "        cy = (bry + bry) / 2\n",
    "        points.append((cx, cy))\n",
    "    return points\n",
    "\n",
    "\n",
    "def tlbr_to_area(boxes):\n",
    "    areas = []\n",
    "    for tlx, tly, brx, bry in boxes:\n",
    "        cx = (brx - tlx)\n",
    "        cy = (bry - tly)\n",
    "        areas.append(abs(cx * cy))\n",
    "    return areas\n",
    "\n",
    "\n",
    "def get_horiz_dist_centre(boxes):\n",
    "    pnts1 = np.array(tlbr_to_center1(boxes[0]))[:, 0]\n",
    "    pnts2 = np.array(tlbr_to_center1(boxes[1]))[:, 0]\n",
    "    return pnts1[:, None] - pnts2[None]\n",
    "\n",
    "\n",
    "def get_horiz_dist_corner_tl(boxes):\n",
    "    pnts1 = np.array(tlbr_to_corner(boxes[0]))[:, 0]\n",
    "    pnts2 = np.array(tlbr_to_corner(boxes[1]))[:, 0]\n",
    "    return pnts1[:, None] - pnts2[None]\n",
    "\n",
    "\n",
    "def get_horiz_dist_corner_br(boxes):\n",
    "    pnts1 = np.array(tlbr_to_corner_br(boxes[0]))[:, 0]\n",
    "    pnts2 = np.array(tlbr_to_corner_br(boxes[1]))[:, 0]\n",
    "    return pnts1[:, None] - pnts2[None]\n",
    "\n",
    "\n",
    "def get_vertic_dist_centre(boxes):\n",
    "    pnts1 = np.array(tlbr_to_center1(boxes[0]))[:, 1]\n",
    "    pnts2 = np.array(tlbr_to_center1(boxes[1]))[:, 1]\n",
    "    return pnts1[:, None] - pnts2[None]\n",
    "\n",
    "\n",
    "def get_area_diffs(boxes):\n",
    "    pnts1 = np.array(tlbr_to_area(boxes[0]))\n",
    "    pnts2 = np.array(tlbr_to_area(boxes[1]))\n",
    "    return abs(pnts1[:, None] - pnts2[None])\n",
    "\n",
    "\n",
    "def get_dist_to_centre_tl(box, cntr=centre):\n",
    "    pnts = np.array(tlbr_to_corner(box))[:, 0]\n",
    "    return abs(pnts - cntr)\n",
    "\n",
    "\n",
    "def get_dist_to_centre_br(box, cntr=centre):\n",
    "    pnts = np.array(tlbr_to_corner_br(box))[:, 0]\n",
    "    return abs(pnts - cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76bfee5a-9063-436f-9eef-fe09d5de2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(boxes, lbls=None, sz1=400):\n",
    "    alpha = sz1\n",
    "    beta = 10\n",
    "    gamma = 5\n",
    "\n",
    "    # vertical_dist, scale by gamma since can't move up or down\n",
    "    vert_dist = gamma * abs(get_vertic_dist_centre(boxes))\n",
    "\n",
    "    # horizontal distance.\n",
    "    horiz_dist = get_horiz_dist_centre(boxes)\n",
    "\n",
    "    # increase cost if object has moved from right to left.\n",
    "    horiz_dist[horiz_dist < 0] = beta * abs(horiz_dist[horiz_dist < 0])\n",
    "\n",
    "    # area of box\n",
    "    area_diffs = get_area_diffs(boxes) / alpha\n",
    "\n",
    "    cost = np.array([vert_dist, horiz_dist, area_diffs])\n",
    "\n",
    "    cost = cost.sum(axis=0)\n",
    "\n",
    "    # add penalty term for different object classes\n",
    "    if lbls is not None:\n",
    "        for i in range(cost.shape[0]):\n",
    "            for j in range(cost.shape[1]):\n",
    "                if lbls[0][i] != lbls[1][j]:\n",
    "                    cost[i, j] += 150\n",
    "    return cost\n",
    "\n",
    "\n",
    "def annotate_class(img, det, class_map, conf=None, colours=None):\n",
    "    if colours is None:\n",
    "        colours = COLOURS\n",
    "    for i, (tlx, tly, brx, bry) in enumerate(det):\n",
    "        txt = class_map[i]\n",
    "        if conf is not None:\n",
    "            txt += f' {conf[i]:1.3f}'\n",
    "        offset = 1\n",
    "        cv2.rectangle(img,\n",
    "                      (tlx - offset, tly - offset + 12),\n",
    "                      (tlx - offset + len(txt) * 12, tly),\n",
    "                      color=colours[i % len(colours)],\n",
    "                      thickness=cv2.FILLED)\n",
    "\n",
    "        ff = cv2.FONT_HERSHEY_PLAIN\n",
    "        cv2.putText(img, txt, (tlx, tly - 1 + 12), fontFace=ff, fontScale=1.0, color=(255,) * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d074187-a55c-43a1-94fc-d1ae9fe77fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_images(left_img, right_img, startTime):\n",
    "    global centre\n",
    "    left_img = imageColorChange(left_img)\n",
    "    right_img = imageColorChange(right_img)\n",
    "\n",
    "    # Stereo image dimensions\n",
    "    sz1, sz2 = right_img.shape[1], right_img.shape[0]\n",
    "    centre = sz1 / 2\n",
    "    # Preprocess images for model input\n",
    "\n",
    "    imgs = [left_img, right_img]\n",
    "\n",
    "    # Get detections from the model\n",
    "    det, lbls, _, _ = get_detections(model, imgs)\n",
    "\n",
    "    # Calculate costs between detected objects\n",
    "    cost = get_cost(det, lbls)\n",
    "\n",
    "    # Perform linear sum assignment to get tracks\n",
    "    tracks = scipy.optimize.linear_sum_assignment(cost)\n",
    "\n",
    "    dists_tl = get_horiz_dist_corner_tl(det)\n",
    "    dists_br = get_horiz_dist_corner_br(det)\n",
    "\n",
    "    # Determine final distances based on closest corner to center\n",
    "    final_dists = []\n",
    "    dctl = get_dist_to_centre_tl(det[0], centre)\n",
    "    dcbr = get_dist_to_centre_br(det[0], centre)\n",
    "\n",
    "    for i, j in zip(*tracks):\n",
    "        if dctl[i] < dcbr[i]:\n",
    "            final_dists.append((dists_tl[i][j], np.array(weights.meta[\"categories\"])[lbls[0]][i]))\n",
    "\n",
    "        else:\n",
    "            final_dists.append((dists_br[i][j], np.array(weights.meta[\"categories\"])[lbls[0]][i]))\n",
    "\n",
    "    tanTheta = (1 / (28.2 - FocalLength)) * (7.05 / 2) * sz1 / 227.710\n",
    "\n",
    "    fd = [i for (i, j) in final_dists]\n",
    "\n",
    "    # find the distance away\n",
    "    dists_away = (7.05 / 2) * sz1 * (1 / tanTheta) / np.array(fd) + FocalLength\n",
    "\n",
    "    cat_dist = []\n",
    "    for i in range(len(dists_away)):\n",
    "        cat_dist.append(f'{np.array(weights.meta[\"categories\"])[lbls[0]][i]} {dists_away[i]:.1f}cm')\n",
    "\n",
    "    t1 = [list(tracks[1]), list(tracks[0])]\n",
    "    for i, imgi in enumerate(imgs[:1]):\n",
    "        deti = det[i].astype(np.int32)\n",
    "        draw_detections(imgi, deti[list(tracks[i])], obj_order=list(t1[i]))\n",
    "        annotate_class(imgi, deti[list(tracks[i])], cat_dist)\n",
    "    print('Time take:', (time.time() - startTime))\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d791e0-b920-4f89-b6b6-7f5b73ab3e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time take: 6.3315722942352295\n",
      "Time take: 6.539424896240234\n",
      "Time take: 6.2370688915252686\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"Image Depth from Left camera\", cv2.WINDOW_NORMAL)\n",
    "for i in range(0, 3):\n",
    "    images = processing_images(\n",
    "        cv2.imread(f'StereoCameraImages/LeftImages/left_image_0{i}.jpg'),\n",
    "        cv2.imread(f'StereoCameraImages/RightImages/right_image_0{i}.jpg'), time.time())\n",
    "    cv2.imshow(\"Image Depth from Left camera\", images[0])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123687a-a13a-4f11-9dbf-588e06fea636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf784eb-8b81-4d31-927e-811b68c3b6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
